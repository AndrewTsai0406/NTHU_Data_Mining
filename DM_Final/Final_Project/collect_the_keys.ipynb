{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This one is going to create a text file that contains all the labeled words\n",
    "\"\"\"\n",
    "import pandas \n",
    "\n",
    "r=open('./material/train_1_update.txt',encoding='utf-8')\n",
    "text=r.read()\n",
    "r.close()\n",
    "\n",
    "article_lists=text.split('\\n--------------------\\n')\n",
    "del(article_lists[-1])\n",
    "processed_ariticles= list(map(lambda x:[x[0],'article_id\\t'+x[1]],[article.split('\\narticle_id\\t') for article in article_lists]))\n",
    "df_list=[]\n",
    "\n",
    "for i,text in enumerate(processed_ariticles):\n",
    "    df_list.append(pandas.DataFrame([x.split('\\t') for x in processed_ariticles[i][1].split('\\n')]))\n",
    "\n",
    "results=pandas.concat(df_list)\n",
    "results.set_axis(results.iloc[0],inplace=True,axis=1)\n",
    "results.drop(0,inplace=True)\n",
    "c=0\n",
    "keys=set()\n",
    "for w in results['entity_text']:\n",
    "    c+=1\n",
    "    keys.add(w)\n",
    "keys.discard(None)\n",
    "\n",
    "\n",
    "r= open('self_defined_words.txt','w')\n",
    "r.write('\\n'.join(sorted(list(keys),key=len,reverse=True)))\n",
    "r.close()\n",
    "#count =2256 len(set)=892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
