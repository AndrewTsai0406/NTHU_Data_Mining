{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                9030      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 19)                304       \n",
      "=================================================================\n",
      "Total params: 10,279\n",
      "Trainable params: 10,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "3740/3740 [==============================] - 9s 2ms/step - loss: 68.7037 - accuracy: 0.9515\n",
      "Epoch 2/2\n",
      "3740/3740 [==============================] - 10s 3ms/step - loss: 73.5627 - accuracy: 0.9584\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This carrys on the work from pre_process_articles.py that does the \n",
    "word embeeding. Now we create an list that stores the information of \n",
    "every articles in terms of their mapping from vectors to labels.\n",
    "\"\"\"\n",
    "\n",
    "def label_and_classification():\n",
    "    import gensim\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    word_vector=gensim.models.KeyedVectors.load_word2vec_format('./pre_trained_wv/wv.txt')\n",
    "    token_list=np.load('./pre_processed_data/token_list.npy',allow_pickle=True)\n",
    "    token_list=token_list.tolist()\n",
    "    \n",
    "    \"\"\"Two list below contain the words' vectors of X and the one-hot encoding labels of Y\"\"\"\n",
    "    X,Y=[],[]\n",
    "    def see_if_token_in_label_list(token,article_label):     \n",
    "        lst=[w[1] for w in article_label]\n",
    "        try:\n",
    "            frt_occurence=lst.index(token[1])\n",
    "        except ValueError:\n",
    "            Y.append([0 if i !=18 else 1 for i in range(19)])\n",
    "            return 18\n",
    "        Y.append([0 if i !=label_mapping[article_label[frt_occurence][4]] else 1 for i in range(19)])\n",
    "        return label_mapping[article_label[frt_occurence][4]]\n",
    "    \n",
    "    label_list=[]\n",
    "    label_mapping={'name':0,'location':1,'time':2,'contact':3,'ID':4,'profession':5,'biomarker':6,\n",
    "               'family':7,'clinical_event':8,'special_skills':9,'unique_treatment':10,'account':11,\n",
    "               'organization':12,'education':13,'money':14,'belonging_mark':15,'med_exam':16,'others':17,'useless':18}\n",
    "    \n",
    "    for article in token_list:\n",
    "        for l in article[1]:\n",
    "            for i in range(3):\n",
    "                l[i]=int(l[i])\n",
    "                \n",
    "        for token in article[0]:\n",
    "            label_list.append(see_if_token_in_label_list(token,article[1])) \n",
    "            try:\n",
    "                X.append(word_vector.get_vector(token[0]))\n",
    "            except TypeError:\n",
    "                X.append(np.zeros(300))\n",
    "    c=0\n",
    "    for v in X:\n",
    "        if v[0]==0:\n",
    "            c+=1\n",
    "                \n",
    "    '''Below tries to build an classifier for final classification'''\n",
    "    number_of_split_train=int(len(X)*0.8)   \n",
    "    train_X,train_Y,test_X,test_Y=X[:number_of_split_train],Y[:number_of_split_train],X[number_of_split_train:],Y[number_of_split_train:] #for banary classifier\n",
    "    \n",
    "    '''\n",
    "    Since the label classes are extremely imbalanced, \n",
    "    we adjust the weights of each class by passing in the weight list to the model.\n",
    "    '''\n",
    "    number_of_label_class=[0 for _ in range(19)]\n",
    "    for i in label_list:\n",
    "        number_of_label_class[i]+=1\n",
    "    weights_class_dict={i:len(label_list)/number_of_label_class[i] if number_of_label_class[i]!=0 else len(label_list) for i in range(19)}        \n",
    "    \n",
    "    \"\"\"adjust the weight of 'useless' class so that we don't value this class too much.\"\"\"\n",
    "    weights_class_dict[18]=30 \n",
    "# =============================================================================\n",
    "#     METRICS = [\n",
    "#           tf.keras.metrics.TruePositives(name='tp'),\n",
    "#           tf.keras.metrics.FalsePositives(name='fp'),\n",
    "#           tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "#           tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "#           tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           tf.keras.metrics.Precision(name='precision'),\n",
    "#           tf.keras.metrics.Recall(name='recall'),\n",
    "#           tf.keras.metrics.AUC(name='auc')]\n",
    "# =============================================================================\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(30,activation=tf.nn.relu,input_shape=(300,)))\n",
    "    model.add(tf.keras.layers.Dense(15,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(15,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(15,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(19,activation=tf.nn.softmax))\n",
    "    model.compile(loss='CategoricalCrossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    EPOCHS,BATCH_SIZE=2,10\n",
    "    model.fit(np.array(train_X),np.array(train_Y),epochs=EPOCHS,batch_size=BATCH_SIZE,class_weight=weights_class_dict)\n",
    "    test_loss,accuracy=model.evaluate(np.array(test_X),np.array(test_Y))\n",
    "    predictions=model.predict(np.array(X))\n",
    "    class_preds = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    \"\"\"see what words are not in 'useless' category\"\"\"\n",
    "    lst=set()\n",
    "    for article,predict in zip(token_list,class_preds):\n",
    "        for token in article[0]:\n",
    "            if predict!=18:\n",
    "                lst.add((token[0],predict))\n",
    "    return lst\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    lst=label_and_classification()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('藥有', 2)('剛結束', 1)('預期', 1)('那種', 1)('這件', 1)('一次', 2)('預感', 1)('顏色會', 2)('一顆', 2)('變化', 2)('班輪', 1)('差別', 1)('上班', 1)('顆一顆', 1)('沒事', 1)('眼屎', 2)('伴侶關', 1)('看什麼樣', 1)('心情', 1)('還好', 2)('耶', 2)('上次', 2)('孫子', 2)('人比', 2)('火龍果', 2)('走', 2)('看看', 2)('嘿對', 2)('下降', 1)('分得', 1)('吃', 2)('嘖嘖嘖', 2)('元氣', 2)('然後也', 1)('泡', 2)('看到', 2)('選', 2)('癢', 2)('買', 2)('跡象', 2)('鼠蹊部', 2)('好好', 1)('抽血', 2)('需要', 2)('一直', 1)('決定', 1)('深', 2)('應該', 2)('一天', 1)('七千二', 2)('滿高', 1)('之下', 1)('黑', 2)('藥', 1)('性病', 1)('行為', 1)('這種', 2)('沒有', 2)('這陣子', 2)('白血球', 2)('OK', 1)('那一樣', 1)('淋巴', 2)('生活', 1)('然後四個', 1)('帶個', 2)('阿還', 2)('知道', 2)('56', 2)('老人家', 2)('目前', 2)('在家', 1)('那為', 2)('較屬', 1)('面覺', 1)('配合', 1)('人有', 2)('六班', 1)('容器', 2)('化痰', 2)('可能', 2)('膜炎', 2)('高風險', 1)('你現', 1)('24', 1)('要開', 2)('我覺', 2)('然後呢', 1)('感冒', 2)('一下', 2)('看電視', 2)('具有', 1)('抗生素', 2)('胯下', 2)('提出', 1)('然後無套', 1)('建議', 1)('係', 2)('回診', 2)('問題', 1)('情況', 1)('現在', 2)('三天', 2)('擔心', 2)('晚上', 1)('費是', 1)('那有', 1)('那天', 2)('禮拜四', 1)('前哨站', 1)('有點', 2)('櫻桃', 2)('奇怪', 2)('上面', 1)('概念', 1)('染病', 1)('⋯', 2)('反正', 1)('後天下午', 1)('比較', 1)('便劑', 2)('禮拜一', 2)('然後都', 1)('不會', 2)('細菌', 2)('太久', 2)('okok', 1)('摸', 2)('想', 1)('恩', 1)('8月21號', 1)('講過', 1)('送', 1)('靈', 2)('緊張', 2)('輕', 2)('挑', 1)('功能', 2)('算是', 1)('只能', 1)('藥給', 2)('天氣熱', 2)('還沒下', 1)('大都', 1)('幫', 2)('大概', 1)('起來', 1)('現場', 1)('接觸', 1)('多顆', 1)('濃度', 1)('每天', 2)('消減', 1)('單純', 1)('葡萄', 2)('嘿氣色', 2)('同意', 1)('心', 1)('下午', 1)('正確', 1)('有大', 2)('那什麼', 1)('兩個禮拜', 2)('梅毒', 1)('2號', 2)('蛤', 1)('看起', 1)('這一個', 2)('痰', 2)('肝', 2)('40', 1)('最近', 2)('正常', 2)('看到', 1)('再開', 2)('以前', 2)('一定', 1)('看醫師', 2)('會不高', 2)('爸', 2)('需要', 1)('帶套', 1)('就當', 1)('應該', 1)('鼻塞', 2)('保護力', 1)('櫃台', 2)('肝功能', 2)('感染', 1)('預防', 1)('戴套', 1)('找', 1)('久', 2)('馬', 1)('腋', 2)('六千二', 2)('你會', 1)('氣管', 2)('禮拜三', 1)('沒關', 2)('保護', 1)('藥我', 2)('其實', 1)('便是', 2)('70', 1)('差', 1)('糾結', 1)('新', 2)('傳染', 2)('太忙', 1)('途徑', 1)('邊領', 2)('不錯', 2)('脖子', 2)('約', 1)('付', 1)('藥有', 1)('太累', 1)('目前', 1)('排出', 2)('忙', 1)('一顆', 1)('裝還', 2)('我問', 1)('有元氣', 2)('很會', 2)('高', 2)('8點', 1)('回來', 1)('PrEP', 1)('先問', 1)('發炎', 2)('天一', 1)('8月22號', 1)('窩', 2)('～', 1)('有連', 1)('會發', 1)('一下', 1)('ok', 1)('還好', 1)('耶', 1)('畢竟', 1)('係', 1)('發', 1)('問題', 2)('咳嗽', 2)('套', 1)('一組', 1)('好來', 1)('家裡', 2)('覺得', 1)('吃藥', 1)('戴', 1)('嚴重', 2)('繁殖', 2)('吃水果', 2)('事', 1)('太麻煩', 1)('痛', 2)('勒', 2)('排', 1)('有什麼', 1)('不癢', 2)('變', 1)('離職', 1)('開放關', 1)('·', 2)('18', 1)('難怪', 2)('剩', 1)('這個月', 1)('隔天', 1)('後天', 1)('鼻水', 2)('很累', 1)('不會', 1)('H', 1)('大夜班', 1)('繼續', 2)('23號', 1)('菜', 1)('小小', 2)('頭會', 2)('濕疹', 2)('軟', 2)('藥是', 2)('刺刺', 2)('多喝水', 2)('6', 1)('藥要', 2)('顆的', 2)('晚餐', 2)('降下', 2)('跑', 1)('現階段', 1)('電影', 1)('試過', 1)('考', 1)('單子', 2)('禮拜五', 1)('包含', 1)('靈的', 2)('頭皮', 2)('照顧', 1)('不要', 2)('同樣', 1)('不太有', 1)('我來問', 1)('開火', 1)('知道', 1)('下次', 2)('還在', 1)('7號', 2)('復', 2)('安全', 2)('開刀', 1)('前天', 2)('藥局', 2)('改變', 2)('不太會', 2)('代表', 1)('鼻涕', 2)('這兩次', 1)('一次性', 1)('睡', 1)('今天', 1)('症狀', 2)('回去', 2)('......', 1)('60', 1)('最少', 2)('一定', 2)('前面', 1)('遇到', 1)('擤', 2)('公司', 1)('說現', 1)('走', 1)('happytime', 1)('開藥膏給', 2)('半年', 2)('感染', 2)('藥膏', 2)('交友', 1)('對覺', 1)('16小時', 1)('過敏', 2)('鬆', 2)('我現', 1)('那要', 1)('筋膜', 2)('一點', 2)('⋯', 1)('ubereats', 1)('性傳', 1)('提早', 2)('紅紅', 2)('差', 2)('清楚', 2)('弄', 1)('本來', 2)('連六', 1)('還沒有', 1)('帶', 2)('兩個', 1)('菜然', 1)('不錯', 1)('病毒', 2)('口罩', 2)('十點', 2)('慢性病', 1)('早早', 1)('意思', 1)('10點', 1)('記得', 2)('藥', 2)('狀況', 1)('兩個現', 1)('想要', 1)('事情', 1)('了解', 2)('足底', 2)('足弓', 2)('假設', 1)('辦法', 1)('出血', 2)('沒有', 1)('一個', 1)('筋', 2)('屎', 2)('藥廠', 1)('小時', 1)('吃法', 1)('然後再', 1)('抹', 2)('回歸到', 1)('每天', 1)('油油的', 2)('眼藥水', 2)('要求', 1)('確認', 1)('性行', 1)('還愉悅', 1)('是不是', 1)('看個', 1)('不用', 2)('濃的', 2)('fell', 1)('眼睛', 2)('下下個月', 2)('兩顆', 1)('高起', 2)('不太準', 2)('懶', 1)('80', 1)('一起', 2)('放在', 1)('工作', 2)('男友', 1)('不準', 2)('不傷', 2)('正常', 1)('累為', 1)('同一', 1)('然後隔', 1)('慾', 1)('黑黑', 2)('上次', 1)('跟頭', 2)('現在', 1)('務型', 1)('每次', 2)('然後咧', 1)('絕對', 1)('會不會', 1)('生性', 1)('累', 1)('吃', 1)('5月7號', 2)('任務型', 1)('6', 2)('這也', 1)('一站', 2)('淡', 2)('完', 1)('7', 2)('流', 2)('氣色', 2)('做', 2)('增加', 2)('之前', 1)('尿', 2)('時間', 1)('一直', 2)('還蠻', 1)('5號', 2)('傳染', 1)('想', 2)('一天', 2)('黑黑的', 2)('會有', 1)('很多', 1)('不要', 1)('撥', 1)('的關', 2)('不好意思', 1)('腎', 2)('軟體', 1)('檢查', 2)('8', 1)('那現', 1)('稍微', 2)('至少', 1)('相關性', 1)('保險', 1)('夠預防', 1)('無套', 1)('回來', 2)('HIV', 1)('鍋店', 1)('這樣講', 1)('程度', 1)('4點', 1)('固炮', 1)('提醒', 1)('feel', 1)('衝得', 2)('～', 2)('的藥', 2)('眼鏡', 2)('幾組', 1)('發', 2)('可能', 1)('囉', 1)('最慢', 1)('傍晚', 1)('聽', 2)('沒吃藥', 2)('兩個月', 2)('多久', 2)('5月2號', 2)('主要', 1)('髮', 2)('我覺', 1)('走路', 2)('過個', 1)('早上', 2)('他會怕', 2)('放心', 1)('套風險', 1)('錢', 1)('外公', 1)('擔心', 1)('體質', 2)('腳底', 2)('看比較', 2)('指數', 2)('怪怪的', 1)('久', 1)('要查', 2)('鼻子', 2)('阿那', 2)('5月5號', 2)('50', 1)('火鍋', 1)('大便', 2)('記得', 1)('比較', 2)('喉嚨', 2)('那什麼樣', 1)('回家', 1)('地方', 2)('通常', 1)('辦法', 2)('對話', 1)('一個', 2)('你給', 2)('一年', 2)('分擔', 1)('改任', 1)('完全', 1)('流鼻涕', 2)('鐵質', 2)('問題講', 2)('差不多', 2)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Below are the words that are categorized tokens with labels and they don't make any sense at all, \n",
    "it's more of a random guess at best.\n",
    "\"\"\"\n",
    "for i in lst:\n",
    "    print(i,end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
